{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 使用字符分割的验证码识别流程\n",
    "\n",
    "### 1. 图像预处理‌\n",
    "\n",
    "-‌‌ ‌灰度化与二值化‌：将彩色验证码转为灰度图，并通过阈值化（如 Otsu 算法）生成二值图像，突出字符轮廓‌35。\n",
    "‌去噪与形态学优化‌：使用高斯模糊消除噪声，通过膨胀（Dilation）和腐蚀（Erosion）连接断裂字符‌35。\n",
    "‌示例代码‌：\n",
    "python\n",
    "Copy Code\n",
    "\n",
    "\n",
    "### 2. 字符分割‌\n",
    "\n",
    "‌投影法‌：根据水平/垂直像素投影分布定位字符边界，适合字符间距较大的场景‌23。\n",
    "‌连通域分析‌：提取图像中的连通区域，筛选面积和宽高符合字符特征的区域‌24。\n",
    "‌区域生长法‌：从种子点扩展，合并相邻像素形成字符区域，适用于无粘连字符‌3。\n",
    "‌粘连字符处理‌：对复杂粘连场景，需结合形态学操作或基于深度学习的语义分割（如 U-Net）‌34。\n",
    "‌3. 数据准备‌\n",
    "‌单字符标注‌：将分割后的单字符图像按类别（0-9、A-Z、a-z）存储至对应文件夹‌12。\n",
    "‌数据增强‌：对单字符图像进行旋转（±10°）、平移（±5%）、缩放（0.9–1.1 倍）以扩充数据集‌25。\n",
    "‌标准化输入‌：统一图像尺寸（如 32×32 像素），归一化像素值至 [0,1]‌13。\n",
    "‌4. 单字符 CNN 模型训练‌\n",
    "‌网络结构‌：\n",
    "python\n",
    "Copy Code\n",
    "model = Sequential([  \n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,1)),  \n",
    "    MaxPooling2D((2,2)),  \n",
    "    Conv2D(64, (3,3), activation='relu'),  \n",
    "    Flatten(),  \n",
    "    Dense(62, activation='softmax')  # 输出 62 类字符概率  \n",
    "])  \n",
    "‌损失函数与优化‌：使用交叉熵损失（CategoricalCrossentropy）和 Adam 优化器‌12。\n",
    "‌训练策略‌：批量大小设为 32–64，训练轮数（Epochs）约 50–100，验证集准确率可达 90% 以上‌14。\n",
    "‌5. 后处理与结果组合‌\n",
    "‌序列还原‌：将单字符预测结果按原始验证码顺序拼接，形成完整字符串‌14。\n",
    "‌纠错规则‌：结合字符上下文（如固定长度、字符类型）修正异常结果（如字母与数字混合场景）‌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "from keras.models import load_model  \n",
    "\n",
    "def preprocess_captcha(image_path):  \n",
    "    # 1. 灰度化与二值化  \n",
    "    img = cv2.imread(image_path)  \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "    binary = cv2.adaptiveThreshold(  \n",
    "        gray, 255,  \n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  \n",
    "        cv2.THRESH_BINARY_INV, 11, 2  \n",
    "    )  \n",
    "\n",
    "    # 2. 去噪与形态学优化  \n",
    "    blurred = cv2.GaussianBlur(binary, (3, 3), 0)  \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  \n",
    "    dilated = cv2.dilate(blurred, kernel, iterations=1)  \n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)  \n",
    "\n",
    "    # 3. 二次二值化与降噪  \n",
    "    _, thresh = cv2.threshold(eroded, 127, 255, cv2.THRESH_BINARY)  \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    for cnt in contours:  \n",
    "        if cv2.contourArea(cnt) < 50:  \n",
    "            cv2.drawContours(thresh, [cnt], -1, 0, -1)  \n",
    "\n",
    "    return thresh  \n",
    "\n",
    "\n",
    "\n",
    "def split_captcha(image_path):\n",
    "    thresh = preprocess_captcha(image_path)  \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    sorted_ctrs = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])  \n",
    "    captchas = []  \n",
    "    for i, ctr in enumerate(sorted_ctrs):  \n",
    "        x, y, w, h = cv2.boundingRect(ctr)  \n",
    "        roi = thresh[y:y+h, x:x+w]  \n",
    "        if w > 10 and h > 10:  \n",
    "            captchas.append(roi)  \n",
    "    return captchas\n",
    "\n",
    "def recognize_captcha(image_path):\n",
    "    captchas = split_captcha(image_path)  \n",
    "    result = []  \n",
    "    for captcha in captchas:  \n",
    "        _, captcha = cv2.threshold(captcha, 127, 255, cv2.THRESH_BINARY)  \n",
    "        captcha = cv2.resize(captcha, (30, 30))  \n",
    "        captcha = captcha.reshape(-1, 30, 30, 1)  \n",
    "        prediction = model.predict(captcha)  \n",
    "        result.append(chr(np.argmax(prediction) + 65))  \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "processed_image = preprocess_captcha(image_path)\n",
    "cv2.imshow('Processed Image', processed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def build_cnn_model(input_shape=(28, 28, 1), num_classes=36):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout层，防止过拟合\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=(28, 28))\n",
    "    img = img_to_array(img) / 255.0  # 数据归一化\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_model(input_shape=(28, 28, 1), num_classes=36)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)  # train_images 和 train_labels 需要提前准备"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
