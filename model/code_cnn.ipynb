{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 使用字符分割的验证码识别流程\n",
    "\n",
    "### 1. 图像预处理‌\n",
    "\n",
    "-‌‌ ‌灰度化与二值化‌：将彩色验证码转为灰度图，并通过阈值化（如 Otsu 算法）生成二值图像，突出字符轮廓‌\n",
    "‌去噪与形态学优化‌：使用高斯模糊消除噪声，通过膨胀（Dilation）和腐蚀（Erosion）连接断裂字符‌\n",
    "\n",
    "\n",
    "\n",
    "### 2. 字符分割‌\n",
    "\n",
    "‌投影法‌：根据水平/垂直像素投影分布定位字符边界，适合字符间距较大的场景‌\n",
    "‌连通域分析‌：提取图像中的连通区域，筛选面积和宽高符合字符特征的区域‌\n",
    "‌区域生长法‌：从种子点扩展，合并相邻像素形成字符区域，适用于无粘连字符‌\n",
    "‌粘连字符处理‌：对复杂粘连场景，需结合形态学操作或基于深度学习的语义分割（如 U-Net）‌\n",
    "\n",
    "### 3. 数据准备‌\n",
    "\n",
    "‌单字符标注‌：将分割后的单字符图像按类别（0-9、A-Z、a-z）存储至对应文件夹‌\n",
    "‌数据增强‌：对单字符图像进行旋转（±10°）、平移（±5%）、缩放（0.9–1.1 倍）以扩充数据集‌\n",
    "‌标准化输入‌：统一图像尺寸（如 32×32 像素），归一化像素值至 [0,1]‌\n",
    "\n",
    "### 4. 单字符 CNN 模型训练‌\n",
    "\n",
    "‌网络结构‌：\n",
    "```python\n",
    "model = Sequential([  \n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,1)),  \n",
    "    MaxPooling2D((2,2)),  \n",
    "    Conv2D(64, (3,3), activation='relu'),  \n",
    "    Flatten(),  \n",
    "    Dense(62, activation='softmax')  # 输出 62 类字符概率  \n",
    "])  \n",
    "```\n",
    "‌损失函数与优化‌：使用交叉熵损失（CategoricalCrossentropy）和 Adam 优化器‌12。\n",
    "‌训练策略‌：批量大小设为 32–64，训练轮数（Epochs）约 50–100，验证集准确率可达 90% 以上‌14。‌\n",
    "\n",
    "### 5. 后处理与结果组合‌\n",
    "\n",
    "‌序列还原‌：将单字符预测结果按原始验证码顺序拼接，形成完整字符串‌14。\n",
    "‌纠错规则‌：结合字符上下文（如固定长度、字符类型）修正异常结果（如字母与数字混合场景）‌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_gray(image):  \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_rgb(image):  \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_captcha(image_path):  \n",
    "    # 1. 灰度化与二值化  \n",
    "    img = cv2.imread(image_path)  \n",
    "    # 转换为灰度图像\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "    # show_gray(gray)\n",
    "    # 自适应阈值二值化\n",
    "    binary = cv2.adaptiveThreshold(  \n",
    "        gray, 255,  \n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,  \n",
    "        cv2.THRESH_BINARY_INV, 15, 20\n",
    "    )  \n",
    "    # 2. 去噪与形态学优化  \n",
    "    # 高斯模糊\n",
    "    blurred = cv2.GaussianBlur(binary, (3, 3), 0)  \n",
    "    # show_gray(blurred)\n",
    "    # 形态学操作\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)) \n",
    "    # 膨胀与腐蚀 \n",
    "    dilated = cv2.dilate(blurred, kernel, iterations=1)  \n",
    "    # 腐蚀\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)  \n",
    "\n",
    "\n",
    "    # 3. 二次二值化与降噪  \n",
    "    _, thresh = cv2.threshold(eroded, 127, 255, cv2.THRESH_BINARY)  \n",
    "    \n",
    "    # 图片轮廓的三个像素点自动填充为黑色\n",
    "    h, w = thresh.shape\n",
    "    thresh[0:3, :] = 0\n",
    "    thresh[:, 0:3] = 0\n",
    "    thresh[h-3:h, :] = 0\n",
    "    thresh[:, w-3:w] = 0\n",
    "\n",
    "    # 连通区域分析\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "\n",
    "    # 过滤小区域\n",
    "    for label in range(1, num_labels):\n",
    "        if stats[label, cv2.CC_STAT_AREA] < 12:\n",
    "            thresh[labels == label] = 0  # 转为黑色\n",
    "\n",
    "    return thresh  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_captcha(image_path):\n",
    "    thresh = preprocess_captcha(image_path) \n",
    "    show_gray(thresh)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    sorted_ctrs = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])  \n",
    "    captchas = []  \n",
    "    for i, ctr in enumerate(sorted_ctrs):  \n",
    "        x, y, w, h = cv2.boundingRect(ctr)  \n",
    "        roi = thresh[y:y+h, x:x+w]  \n",
    "        if w < 8 and h < 10:  \n",
    "            continue\n",
    "        if h < 28 or w < 28:\n",
    "            padded = np.zeros((28, 28), dtype=np.uint8)\n",
    "            padded[(28-h)//2:(28-h)//2+h, (28-w)//2:(28-w)//2+w] = captchas[i]\n",
    "            \n",
    "        else:\n",
    "            show_gray(roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取目录下所有png文件\n",
    "image_dir = 'D:\\\\vscode\\\\project\\\\captcha_ocr\\\\data\\\\'\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "\n",
    "# 处理每个图片文件\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    print(image_file)\n",
    "    processed_image = preprocess_captcha(image_path)\n",
    "    show_gray(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def build_cnn_model(input_shape=(28, 28, 1), num_classes=36):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout层，防止过拟合\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=(28, 28))\n",
    "    img = img_to_array(img) / 255.0  # 数据归一化\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_model(input_shape=(28, 28, 1), num_classes=36)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)  # train_images 和 train_labels 需要提前准备"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
